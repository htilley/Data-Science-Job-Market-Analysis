{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA SCIENCE JOB MARKET ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Web Scraping using Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "Error",
     "evalue": "Direct kernel connection broken",
     "traceback": [
      "Error: Direct kernel connection broken",
      "at b.getDisposedError (/Users/harry/.vscode/extensions/ms-toolsai.jupyter-2021.5.745244803/out/client/extension.js:32:765475)",
      "at f.handleCodeRequest (/Users/harry/.vscode/extensions/ms-toolsai.jupyter-2021.5.745244803/out/client/extension.js:49:521810)",
      "at /Users/harry/.vscode/extensions/ms-toolsai.jupyter-2021.5.745244803/out/client/extension.js:49:535788",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:97:5)"
     ]
    }
   ],
   "source": [
    "#import necessary packages\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#create an instance of browser\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "#creating a dictionary for storing the information after scraping\n",
    "jobs={\"roles\":[],\n",
    "     \"companies\":[],\n",
    "     \"locations\":[],\n",
    "     \"experience\":[],\n",
    "     \"skills\":[]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate over first 30 pages; each page contains 20 results\n",
    "#for each job we will scrape the role,company, location, experience, skills\n",
    "\n",
    "for i in range(50):\n",
    "    driver.get(\"https://www.naukri.com/data-scientist-jobs-{}\".format(i))\n",
    "    time.sleep(3)\n",
    "    lst=driver.find_elements_by_css_selector(\".jobTuple.bgWhite.br4.mb-8\")\n",
    "    \n",
    "    for job in lst:\n",
    "        driver.implicitly_wait(10)\n",
    "        role=job.find_element_by_css_selector(\"a.title.fw500.ellipsis\").text\n",
    "        company=job.find_element_by_css_selector(\"a.subTitle.ellipsis.fleft\").text\n",
    "        location=job.find_element_by_css_selector(\".fleft.grey-text.br2.placeHolderLi.location\").text\n",
    "        exp=job.find_element_by_css_selector(\".fleft.grey-text.br2.placeHolderLi.experience\").text\n",
    "        skills=job.find_element_by_css_selector(\".tags.has-description\").text\n",
    "        jobs[\"roles\"].append(role)\n",
    "        jobs[\"companies\"].append(company)\n",
    "        jobs[\"locations\"].append(location)\n",
    "        jobs[\"experience\"].append(exp)\n",
    "        jobs[\"skills\"].append(skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "DS_jobs_df=pd.DataFrame(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_jobs_df.to_csv(\"DataScience_jobs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_jobs_df=pd.read_csv(\"DataScience_jobs.csv\", index_col=0)\n",
    "DS_jobs_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets check if our data have any null values\n",
    "DS_jobs_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets drop the missing values\n",
    "DS_jobs_df=DS_jobs_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#lets check if our data have any dupplicate data\n",
    "DS_jobs_df[DS_jobs_df.duplicated(subset=[\"roles\",\"companies\",\"roles\",\"locations\",\"skills\"])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"print(\"Before dropping duplicates : \",DS_jobs_df.shape)\n",
    "DS_jobs_df.drop_duplicates(keep=\"first\",inplace=True)\n",
    "print(\"After dropping duplicates : \"DS_jobs_df.shape)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets lower case all the strings to avoid redundancy\n",
    "DS_jobs_df=DS_jobs_df.apply(lambda x: x.astype(str).str.lower())\n",
    "\n",
    "#there are more than one location and skill are attcahed to each job, so lets split locations and jobs.\n",
    "DS_jobs_df.skills=[skill.split(\"\\n\") for skill in DS_jobs_df.skills]\n",
    "DS_jobs_df.locations=[location.split(\",\") for location in DS_jobs_df.locations]\n",
    "DS_jobs_df[15:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Location wise Data science jobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_jobs_df.locations.apply(pd.Series).stack().str.strip().value_counts()[:10].plot.pie(figsize=(12,10),startangle=50,autopct='%1.1f%%',fontsize=15)\n",
    "plt.title(\"Location Wise Data scientist Jobs\",fontsize=30)\n",
    "\n",
    "#https://medium.com/@krishnakummar/donut-chart-with-python-matplotlib-d411033c960b\n",
    "centre_circle = plt.Circle((0,0),0.72,color='gray', fc='white',linewidth=1.25)\n",
    "fig = plt.gcf()\n",
    "fig.gca().add_artist(centre_circle)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observations:\n",
    "1. Bangalore tops the list with almost 38% of the total jobs.\n",
    "2. Top three cities Bangalore,Mumbai, Hyderabad and Pune constitues almost 72% of the total jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Companies with more Data science openings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_jobs_df[\"companies\"].value_counts()[:10].plot.pie(figsize=(12,10),explode=[0.03,0.04,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05],shadow=True, startangle=40,autopct='%1.1f%%',fontsize=20)\n",
    "plt.title(\"Companies with more job postings\",fontsize=35)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "1. Analytics vidya tops the list with 17% of the total job listings.\n",
    "2. there are quite a few consultancies activey recruiting for their clients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Data Scientist roles in demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Roles\n",
    "DS_jobs_df[\"roles\"].value_counts()[:10].plot.bar(figsize=(8,5),fontsize=10,color=\"y\")#(figsize=(10,10),explode=[0.05,0.04,0.05,0,0,0,0,0,0,0],shadow=True, startangle=50,autopct='%1.1f%%')\n",
    "plt.xticks(rotation=45,ha='right')\n",
    "plt.title(\"Data Scientist Roles\",fontsize=22)\n",
    "plt.ylabel(\"No of Vacancies\",fontsize=15,rotation=90)\n",
    "plt.xlabel(\"Roles\",fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "1. Data science roles are mostly termed with data scientist role. followed by senior data scientist and lead data scientist roles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Desired Experience for Data science jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_jobs_df[\"experience\"].value_counts()[:10].plot.barh(figsize=(8,5),fontsize=13,color=\"b\")\n",
    "plt.xlabel(\"No.of Vacancies\",fontsize=18)\n",
    "plt.ylabel(\"Experience\",fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "1. There seems to more vacancies for people with a good experience.\n",
    "2. Candidates with atleast 2 years of experience have a fair opportunities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Skills required for a Data science job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_jobs_df.skills.apply(pd.Series).stack().value_counts()[:32].plot(kind=\"bar\",figsize=(18,6),fontsize=15,color=\"r\")\n",
    "plt.xticks(rotation=50,ha='right')\n",
    "#plt.title(\"Top Skills for Data science\",fontsize=25)\n",
    "plt.ylabel(\"No.of Vacancies\",fontsize=20)\n",
    "plt.xlabel(\"Top Skills for Data science\",fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "1. looks clumsy right lets break it down, the reason i included top 30 skills beacuse of the vast fields covered by Data science.\n",
    "2. we will go one by one sub fields and compare their peers in that to get the better understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets convert the skills column into a seperate DataFrame, which makes things easy for preo processing\n",
    "jj=pd.DataFrame(DS_jobs_df.skills.apply(pd.Series).stack().value_counts()).reset_index()\n",
    "jj.columns=[\"skills\",\"count\"]\n",
    "jj.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.1. Must Have Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first find the top skills for Data science in general\n",
    "datascience={}\n",
    "datascience['statistics']=jj[\"count\"][jj['skills'].str.contains('stat', regex=True)].sum()\n",
    "datascience['machine_learning']=jj[\"count\"][jj['skills'].str.contains('machine |^ml', regex=True)].sum()\n",
    "datascience['data_analysis']=jj[\"count\"][jj['skills'].str.contains('data ana', regex=True)].sum()\n",
    "datascience['data_mining']=jj[\"count\"][jj['skills'].str.contains('mining', regex=True)].sum()\n",
    "datascience['nlp']=jj[\"count\"][jj['skills'].str.contains('nlp|natural', regex=True)].sum()\n",
    "datascience['computer_vision']=jj[\"count\"][jj['skills'].str.contains('computer vision', regex=True)].sum()\n",
    "datascience['deep_learning']=jj[\"count\"][jj['skills'].str.contains('deep learning', regex=True)].sum()\n",
    "datascience['big_data']=jj[\"count\"][jj['skills'].str.contains('big', regex=True)].sum()\n",
    "from operator import itemgetter\n",
    "datascience=dict(sorted(datascience.items(), key=itemgetter(1),reverse=True))\n",
    "datascience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(datascience.keys(),datascience.values(),color=[\"#FE6363\",\"#66FA72\",\"#6B89F9\",\"c\",\"y\",\"pink\",\"#63FCFE\",\"#DD63FE\"])\n",
    "plt.xticks(rotation=80,fontsize=15)\n",
    "plt.title(\"Must have skills\",fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.2. Languauges in demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages={}\n",
    "languages[\"python\"]=jj[\"count\"][jj['skills'].str.contains('python', regex=True)].sum()\n",
    "languages[\"r\"]=jj[\"count\"][jj['skills'].str.contains('^r$', regex=True)].sum()\n",
    "languages[\"matlab\"]=jj[\"count\"][jj['skills'].str.contains('matlab', regex=True)].sum()\n",
    "languages[\"java\"]=jj[\"count\"][jj['skills'].str.contains('java$', regex=True)].sum()\n",
    "languages[\"c++\"]=jj[\"count\"][jj['skills'].str.contains('c\\+', regex=True)].sum()\n",
    "languages[\"sas\"]=jj[\"count\"][jj['skills'].str.contains('sas', regex=True)].sum()\n",
    "\n",
    "#to identify the Sql first and then seperate the nosql from the list\n",
    "sql=jj[jj['skills'].str.contains('sql', regex=True)]\n",
    "languages[\"sql\"]=sql[\"count\"][~sql['skills'].str.contains('no', regex=True)].sum()\n",
    "\n",
    "#to sort the dictionary\n",
    "languages=dict(sorted(languages.items(), key=itemgetter(1),reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.bar(languages.keys(),languages.values(),color=[\"r\",\"g\",\"b\",\"c\",\"y\",\"pink\",\"m\"])\n",
    "plt.xticks(rotation=45,fontsize=15)\n",
    "plt.title(\"Programming languages for Data science\",fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.3. Deep learning frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frameworks={}\n",
    "frameworks['tensorflow']=jj[\"count\"][jj['skills'].str.contains('tensor', regex=True)].sum()\n",
    "frameworks['keras']=jj[\"count\"][jj['skills'].str.contains('keras', regex=True)].sum()\n",
    "frameworks['pytorch']=jj[\"count\"][jj['skills'].str.contains('torch', regex=True)].sum()\n",
    "plt.bar(frameworks.keys(),frameworks.values(),color=[\"g\",\"b\",\"c\"],width=.5)\n",
    "plt.xticks(rotation=70,fontsize=15)\n",
    "plt.title(\"Deep learning Frameworks\",fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.5. Clouds for Data Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets find the skills based on cloud providers\n",
    "cloud={}\n",
    "cloud['aws']=jj[\"count\"][jj['skills'].str.contains('aws', regex=True)].sum()\n",
    "cloud['azure']=jj[\"count\"][jj['skills'].str.contains('azure', regex=True)].sum()\n",
    "cloud['gcp']=jj[\"count\"][jj['skills'].str.contains('gcp')].sum()\n",
    "plt.bar(cloud.keys(),cloud.values(),color=[\"m\",\"y\",\"pink\"],width=.45)\n",
    "plt.xticks(rotation=45,fontsize=15)\n",
    "plt.title(\"Clouds for Data Science\",fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.6. Big data technologies for Data science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdata={}\n",
    "bigdata[\"spark\"]=jj[\"count\"][jj['skills'].str.contains('spark', regex=True)].sum()\n",
    "bigdata[\"hadoop\"]=jj[\"count\"][jj['skills'].str.contains('hadoop', regex=True)].sum()\n",
    "bigdata[\"hive\"]=jj[\"count\"][jj['skills'].str.contains('hive', regex=True)].sum()\n",
    "bigdata[\"kafka\"]=jj[\"count\"][jj['skills'].str.contains('kafka', regex=True)].sum()\n",
    "\n",
    "plt.bar(bigdata.keys(),bigdata.values(),color=[\"black\",\"purple\",\"grey\",\"blue\"],width=0.6)\n",
    "plt.xticks(rotation=45,fontsize=15)\n",
    "plt.title(\"Big Data technologies\",fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.7. Data Visualization tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools\n",
    "tools={}\n",
    "tools[\"tableau\"]=jj[\"count\"][jj['skills'].str.contains('tableau', regex=True)].sum()\n",
    "tools[\"power_bi\"]=jj[\"count\"][jj['skills'].str.contains('power bi', regex=True)].sum()\n",
    "\n",
    "\n",
    "plt.bar(tools.keys(),tools.values(),color=[\"orange\",\"blue\"],width=(0.4))\n",
    "plt.xticks(rotation=45,fontsize=15)\n",
    "plt.title(\"Visualization Tools\",fontsize=20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python376jvsc74a57bd0dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}